@def title = "Publication Summaries"

### Seismic wavefield reconstruction using a preconditioned wavelet-curvelet compressive sensing approach

Seismic data is normally recorded on a per-channel basis - each instrument writes out a file with the motion of the earth recorded at constantly sampled times. However, we know that the motion satisfies the seismic wave equation, so there should be a way to optimally interpolate all of these recordings in space. We use compressive-sensing, a technique developed for machine vision, to create an optimal interpolation scheme for seismic data that respects wave physics and so allows us to perform innovative new analyses of the seismic wavefield. 


### Probabalistic lowermost mantle P-Wave tomography from hierarchical Hamiltonian Monte Carlo and model parametrization cross-validation

The structure of the Earth is dominated by three primary interfaces --- the surface, the Core-Mantle Boundary (CMB), and the Inner Core boundary. The Core-Mantle Boundary is potentially the most interesting of these, because it strongly controls the heat flux from the core, and hence has wide ranging implications for flow in the mantle and the generation of Earth's magnetic field. The area of the mantle just above the CMB is known as the lowermost mantle and is particularly complex. In this study, we used recent developments in imaging science to provide constraints on just how complex the lowermost mantle is, using a unique dataset that was particularly sensitive to short lengthscale structures. We found that our data required increased short lengthscale complexity compared to existing datasets, suggesting a "patchier" lowermost mantle than is often assumed.  

### Geometric and Level Set Tomography using Ensemble Kalman Inversion

Tomography refers to the process by which we infer the hidden internal structure of an object by sending energy through it, rather than by destructive testing. Most people would be familiar with the medical CT scan (computed tomography) which uses the attenuation of x-rays through the body to create detailed, non-invasive images. We can use a similar idea to create images of the interior of the earth using seismic waves; however because the imaging geometry and propagation physics are much less favorable than in the medical setting, seismic images are much harder to interpret. We propose a method of simplifying the way that seismic images are described during tomography, to make them more robust and interpretable. We use a mixture of explicit geological features such as faults, and boundaries between geological units described implicitly by a mathematical object known as a level set. This allows us to image sharp features much more cleanly than using traditional seismic techniques. 


### Did Oldham Discover the Core After All? Handling Imprecise Historical Data with Hierarchical Bayesian Model Selection Methods

One of the most important developments of early 20th century Earth science was determination that the Earth was made up of multiple layers with wildly different physical characteristics. Probably the most important study during this period was R.D. Oldham's 1906 paper, which synthesised observations of multiple earthquakes at seismometers across the world to build a comprehensive picture of how long it took seismic waves to travel through the deep Earth. On the basis of analysing this data, Oldham correctly proposed that the Earth had a core, distinct from the material above it. However, it turned out that while Oldham's conclusions were correct, his analysis was totally wrong, and in fact used data that had nothing to do with the core --- however, part of his data may have been sufficient to "discover" the core correctly, had Oldham analysed it appropriately. We use this significant (and fun) historical dataset to develop new statistical techniques for treating historical seismic data, which is often riddled with imprecision and errors. In doing so, we found that Oldham did in fact have sufficient data to discover the core after discarding his incorrect analyses, and provided a useful tool to the geophysical community for treating historical data.

### Rayleigh-Wave H/V via Noise Cross Correlation in Southern California

Ambient Noise Cross-Correlation is a technique that allows us to use the parts of seismograms that we would normally throw away to simulate an earthquake located at any seismometer. As such, it has become a very popular technique, especially in the study of Rayleigh waves, which are seismic waves that are trapped along the surface. These waves have a characteristic rolling motion — any point in a Rayleigh wave moves in an oval. The ratio of the long vs short axis of this oval (the H/V ratio) turns out to be very sensitive to the structure of the Earth near the surface. We calculated H/V ratios for all of the stations in Southern California, which gave use a new dataset constraining the near surface of this important, earthquake-prone region. 

### Strong, Multi-Scale Heterogeneity in Earth’s Lowermost Mantle

The lowermost mantle refers to the region of the Earth, roughly half-way towards its center, where normal rock gives way to the liquid iron-nickel alloy of the outer core. Because of this extreme transition, it is one of the most interesting parts of the Earth. Previous robust studies of the area have mostly used seismic data which averages over large patches of the lowermost mantle, leading to an image of the lowermost mantle dominated by two large features known as low velocity provinces. We use data with sharper sensitivity to show that the picture in the lowermost mantle is in fact much more complicated, and that the low velocity provinces are less distinct than the previous studies had suggested. 

### A method of spherical harmonic analysis in the geosciences via hierarchical Bayesian inference

Spherical harmonic analysis turns data defined by coordinates on the surface of a sphere (like the Earth, approximately) into a representation based on resonant frequencies, which is useful for many types of further studies. There are fast ways to do this if the data is regularly distributed on the sphere, but for irregular distributions spherical harmonic analysis is quite hard. We developed a new statistical method for spherical harmonic analysis using random sampling to produce uncertainty estimates of the transform. 

### A single-probe-beam double-heterodyne polarimeter-interferometer for plasma Faraday rotation measurements

Commercial nuclear fusion has long been a holy grail of clean energy production, promising to totally replace baseline fossil fuel generators and providing a useful counterbalance to fickle wind and solar. However, despite much promise, fusion has proven to be an engineering nightmare, and so has yet to realize its potential. One of the key considerations for fusion production is accurate metrics of the internal state of the plasma inside the generator. The plasma is the burning fuel of fusion, analagous to ignited gasoline in an internal combustion engine. As an undergraduate research project, we developed a novel microwave-based sensor for determining the physical properties of a test plasma. Of note was that we were an early adopter of 3D printing for custom scientific equipment, in this case a particular microwave-optical element of the sensor.

